model: "distilbert-base-uncased"
task: "MRPC"

output_dir: "/work/Results" #"/Volumes/Expansion"
only_subset: False

training_args:
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  num_train_epochs: 87
  logging_dir: "logs"
  logging_steps: 100
  evaluation_strategy: "steps"
  save_steps: 1000