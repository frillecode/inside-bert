model: "distilbert-base-uncased"
task: "MNLI"

timestamp: "2024-08-20_00-26-53"

output_dir: /work/Results #"/Volumes/Expansion/"

window: 100
step_cutoff: 5000

training_args:
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  num_train_epochs: 3
  logging_dir: "logs"
  logging_steps: 100
  evaluation_strategy: "steps"
  save_steps: 1000