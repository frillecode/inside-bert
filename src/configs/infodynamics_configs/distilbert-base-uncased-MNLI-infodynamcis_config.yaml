model: "distilbert-base-uncased"
task: "MNLI"

timestamp: "2024-07-31_12-23-26"

output_dir: "/Volumes/Expansion/"

window: 100
step_cutoff: 5000

training_args:
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  num_train_epochs: 100
  logging_dir: "logs"
  logging_steps: 50
  evaluation_strategy: "steps"
  save_steps: 5000